# Generative AI with Large Language Models (LLMs)

Through the **Generative AI with Large Language Models (LLMs)** course, I have gained a solid understanding of how generative AI functions and how to apply it in practical scenarios.

By completing this course, I have:
* Developed a comprehensive understanding of generative AI, including the key steps in the LLM-based AI lifecycleâ€”ranging from data collection and model selection to performance evaluation and deployment.
* Learned about the transformer architecture behind LLMs, how they are trained, and how fine-tuning allows for the adaptation of LLMs to specific tasks and use cases.
* Gained insight into empirical scaling laws and how they can be leveraged to optimize model performance based on dataset size, computational resources, and inference requirements.
* Applied modern training, tuning, inference, and deployment techniques to ensure optimal performance while working within the constraints of a given project.
* Understood the challenges and opportunities that generative AI presents to businesses, learning from the experiences of industry researchers and practitioners.

This course was ideal for developers like me who had a foundational knowledge of LLMs and best practices for training and deploying them. It has equipped me with the knowledge and skills to make better decisions within a company and allowed me to quickly prototype real-world solutions. Overall, it has provided me with a practical understanding of how to leverage this exciting technology.

## Week 1
Generative AI Use Cases, Project Lifecycle, and Model Pre-training

### What I Learned:
* I now understand the difference between model pre-training and fine-tuning, and how both processes play crucial roles in improving generative AI models.
* I gained knowledge of key terms such as generative AI, large language models, prompts, and the transformer architecture that powers LLMs.
* I learned about the steps involved in the LLM-based generative AI lifecycle and the various factors that influence decisions at each stage of the lifecycle.
* I explored computational challenges during model pre-training and learned techniques to minimize memory footprint.
* I familiarized myself with scaling laws and how they relate to dataset size, compute budget, inference needs, and more.

[Lab 1 - Summarize Dialogue](https://github.com/nsurya-0698/genAI-with-Large-Language-Models/blob/main/Week-One/Lab_1_summarize_dialogue.ipynb)

[Week 1 Quiz](https://github.com/nsurya-0698/genAI-with-Large-Language-Models/blob/main/Week-One/Week-1_Quiz.md)

## Week 2
Fine-tuning and Evaluating Large Language Models

### What I Learned:
* I learned how fine-tuning LLMs using instruction-based prompt datasets can significantly improve model performance on specific tasks.
* I gained an understanding of catastrophic forgetting and discovered strategies to mitigate this issue during model training.
* I explored the concept of Parameter-efficient Fine Tuning (PEFT) and learned how it reduces computational costs and avoids catastrophic forgetting.
* I delved into how fine-tuning with instructions and prompt datasets can enhance LLM performance across various tasks.

[Lab 2 - Fine-tune a Generative AI Model for Dialogue Summarization](Add link)

[Week 2 Quiz](Add link)

## Week 3
Reinforcement Learning and LLM-Powered Applications

### What I Learned:
* I gained a deeper understanding of how Reinforcement Learning from Human Feedback (RLHF) improves model alignment and performance.
* I explored how human feedback is used to train reward models for RLHF and its effect on LLMs.
* I learned about chain-of-thought prompting and how it can enhance reasoning and planning abilities in LLMs.
* I explored the challenges LLMs face, such as knowledge cut-offs, and learned about information retrieval and augmentation techniques to address these challenges.

[Lab 3 - Fine-tune FLAN-T5 with Reinforcement Learning for Positive Summaries](Add link)

[Week 3 Quiz](Add link)